# Исправление подключения к ML Service

## Проблема
Ошибка "Ошибка подключения к серверу сокращения" возникает, когда фронтенд (локально) не может подключиться к ML Service (в Docker).

## Решения

### 1. Проверьте, что ML Service запущен

```bash
# Проверьте статус контейнера
docker ps | findstr ml_service

# Если не запущен, запустите:
docker-compose up -d ml_service

# Проверьте логи
docker-compose logs ml_service
```

### 2. Проверьте доступность ML Service

Откройте в браузере: `http://localhost:8000/docs`

Если страница не открывается, значит ML Service не запущен или порт не проброшен.

### 3. Проверьте переменные окружения

В `.env` файле в корне проекта добавьте (если нет):

```env
NEXT_PUBLIC_ML_SERVICE_URL=http://localhost:8000
```

Или в `frontend/.env.local`:

```env
NEXT_PUBLIC_ML_SERVICE_URL=http://localhost:8000
```

### 4. Перезапустите фронтенд

После изменения переменных окружения:

```bash
cd frontend
npm run dev
```

### 5. Если ML Service в Docker, а фронтенд локально

Это нормально! Главное:
- Порт 8000 должен быть проброшен из Docker (`ports: - "8000:8000"`)
- ML Service должен быть доступен на `localhost:8000`
- В браузере откройте `http://localhost:8000/health` - должно вернуть статус

### 6. Проверьте CORS

ML Service должен разрешать запросы с `localhost:3000`. В коде уже настроено `allow_origins=["*"]`, так что это не должно быть проблемой.

## Логирование прогресса

Теперь при сокращении текста вы увидите:
- "Подготовка к сокращению..."
- "Подключение к серверу обработки..."
- "Обработка текста моделью..." (самый долгий этап - 10-30 секунд)
- "Форматирование результата..."

## Почему Gazeta долго работает?

Модель Gazeta (mbart_ru_sum_gazeta):
- Большая модель (~2-3 GB)
- При первом использовании загружается в память (10-30 секунд)
- Генерация сокращения занимает 10-30 секунд
- Это нормально для такой модели

**Итого:** Ожидайте 20-60 секунд на первое сокращение, последующие будут быстрее (модель уже в памяти).

